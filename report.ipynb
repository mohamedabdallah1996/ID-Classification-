{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID Classification Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, after reading the task I think about the data. how to collect large amount of data for the 2 classes (real and printed). I get 5 ID cards and printed them. so, Now I have 5 images of real ID and 5 images of printed ID."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best solution to generate more data without easily is to apply `data augmentation`. So, I decided to generate about 500 images for each class with data augmentation. now I have 1000 images for the 2 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://debuggercafe.com/image-transformation-using-opencv-and-python/ <br>\n",
    "https://www.kaggle.com/hanzh0420/image-augmentation-with-opencv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Really, Data augmentation was the first challenge!. after augmenting the data, the next challenge was splitting the data and structuring them into train and test folders. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6 <br>\n",
    "https://stackoverflow.com/questions/38250710/how-to-split-data-into-3-sets-train-validation-and-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have quite good amount of data for our model. the next step is to preprocess these data. I made a simple and critical preprocessing step. it's resizing the images to a fixed size. this is really very important step because the model expects to have all the images with the same shape.\n",
    "There are other techniques for data preprocessing of images such as: standarization, dimensionality reduction and removing noise from the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/image-pre-processing-c1aec0be3edf <br>\n",
    "https://machinelearningmastery.com/how-to-load-and-manipulate-images-for-deep-learning-in-python-with-pil-pillow/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next challenge is to choose the best model based on your data. I chose `Local Binary Patterns (LBP)`. it's a simple algorithm aims to extract the feature vectors from your images then you choose another machine learning classification algorithm to match these vector features with the image label. after all, I chose `Linear Support Vector Machine (LSVM)`. it's a simple model to apply this binary classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.pyimagesearch.com/2015/12/07/local-binary-patterns-with-python-opencv/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After building a model, We want to see how the model performs on the unseen data (test data). Since our data is balanced and preprocessed, our model reached to a good accuracy with `LBP` and `LSVM` algorithms. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
